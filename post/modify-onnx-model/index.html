<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>裁剪 ONNX 模型 - Yuko's Note</title>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NC0VXE56DE"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NC0VXE56DE")}</script><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Yuko Hu"><meta name=description content="手邊的專題需要用 ResNet 模型驗證 DLA simulator 運算正確性，但是因為模型太大，希望可以把模型依照 stage 分割，方便漸進式測試。為了達成這件事查了不少資料，順手紀錄一下分割的過程。
"><meta name=keywords content="Yuko,yuko29"><meta name=generator content="Hugo 0.129.0 with theme even"><link rel=canonical href=http://yuko29.github.io/post/modify-onnx-model/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@100..900&family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel=stylesheet><link href=/sass/main.min.65ba10c33328e29aa9919dd2d128178677d70bcc8e284e9829109ce84f8bb988.css rel=stylesheet><meta property="og:url" content="http://yuko29.github.io/post/modify-onnx-model/"><meta property="og:site_name" content="Yuko's Note"><meta property="og:title" content="裁剪 ONNX 模型"><meta property="og:description" content="手邊的專題需要用 ResNet 模型驗證 DLA simulator 運算正確性，但是因為模型太大，希望可以把模型依照 stage 分割，方便漸進式測試。為了達成這件事查了不少資料，順手紀錄一下分割的過程。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-06-30T02:23:09+08:00"><meta property="article:modified_time" content="2022-06-30T02:23:09+08:00"><meta property="article:tag" content="Onnx"><meta itemprop=name content="裁剪 ONNX 模型"><meta itemprop=description content="手邊的專題需要用 ResNet 模型驗證 DLA simulator 運算正確性，但是因為模型太大，希望可以把模型依照 stage 分割，方便漸進式測試。為了達成這件事查了不少資料，順手紀錄一下分割的過程。"><meta itemprop=datePublished content="2022-06-30T02:23:09+08:00"><meta itemprop=dateModified content="2022-06-30T02:23:09+08:00"><meta itemprop=wordCount content="993"><meta itemprop=keywords content="Onnx"><meta name=twitter:card content="summary"><meta name=twitter:title content="裁剪 ONNX 模型"><meta name=twitter:description content="手邊的專題需要用 ResNet 模型驗證 DLA simulator 運算正確性，但是因為模型太大，希望可以把模型依照 stage 分割，方便漸進式測試。為了達成這件事查了不少資料，順手紀錄一下分割的過程。"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Yuko's Note</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/about><li class=mobile-menu-item>About</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Yuko's Note</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/about>About</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>裁剪 ONNX 模型</h1><div class=post-meta><span class=post-time>2022-06-30</span><div class=post-category><a href=/categories/deep-learning/>Deep Learning</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><ul><li><a href=#onnx-格式>ONNX 格式</a></li><li><a href=#裁剪>裁剪</a></li><li><a href=#結尾>結尾</a></li></ul></li></ul></nav></div></div><div class=post-content><p>手邊的專題需要用 ResNet 模型驗證 DLA simulator 運算正確性，但是因為模型太大，希望可以把模型依照 stage 分割，方便漸進式測試。為了達成這件事查了不少資料，順手紀錄一下分割的過程。</p><h2 id=onnx-格式>ONNX 格式</h2><p>切割之前要先了解 ONNX 是怎麼儲存模型資料的，可以參考下面幾篇文章：</p><ul><li><a href=https://zhuanlan.zhihu.com/p/346511883>ONNX学习笔记</a></li><li><a href=https://ithelp.ithome.com.tw/articles/10227825>Day 28: 再造訪 ONNX Graph</a></li></ul><p>關於 ONNX 詳細的格式訊息詳細的寫在這份文件：</p><ul><li><a href=https://github.com/onnx/onnx/blob/main/onnx/onnx.proto>onnx.proto</a></li></ul><p>關於 Protocol Buffer 定義方式，可以參考 Google 的文件：</p><ul><li><a href=https://developers.google.com/protocol-buffers/docs/cpptutorial>Protocol Buffer Basics: C++</a></li></ul><p>根據上面的資訊，當載入一個 ONNX 模型，它的結構大概如下</p><ul><li>model：ModelProto 類型，包含一些模型的版本訊息和一個 GraphProto<ul><li>graph：GraphProto 類型，裡面包含 4 個 repeated 數組（可視為 dynamically sized array）<ul><li>node： NodeProto 類型，裡面存放所有的 compute operator</li><li>input： ValueInfoProto 類型，裡面放了模型的 input operator</li><li>output： ValueInfoProto 類型，裡面放了模型的 output operator</li><li>initializer： TensorProto 類型，裡面放了所有的權重參數</li></ul></li></ul></li></ul><h2 id=裁剪>裁剪</h2><p>知道了 ONNX 的結構後，就能很容易的規劃裁剪模型的步驟了，裁剪 ONNX 模型的步驟可如下：</p><ol><li>針對 node 取出需要的 compute operator，把其他不用的移除掉</li><li>製作新的 output operator 並替換上去</li><li>不用的權重參數可以從 initializer 內移掉（這次我沒有這麼做，因為我不需要）</li></ol><p>我要裁剪的 model 是 ResNet V1 的 <a href=https://github.com/onnx/models/tree/main/vision/classification/resnet>ResNet18</a>，來自 ONNX Model Zoo。</p><p>Ok，接下來就可以開始切了。
以下說明 operator 和 node 會混著用，兩者是同一個意思。</p><p>首先先載入 model。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>onnx</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>onnx</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;resnet18-v1-7/resnet18-v1-7.onnx&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>接著取出需要的 compute operator，清除掉原本的 node 後再把需要的加回去。
這裡需要知道這些 operator 的 index 位置，我是沿著 Add 這個 operator 切，第一個 Add operator 是 index 10 的 node。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>oldnodes</span> <span class=o>=</span> <span class=p>[</span><span class=n>n</span> <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>node</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>newnodes</span> <span class=o>=</span> <span class=n>oldnodes</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>10</span><span class=p>]</span> <span class=c1># stage1_plus0</span>
</span></span><span class=line><span class=cl><span class=k>del</span> <span class=n>model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>node</span><span class=p>[:]</span> 
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>node</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>newnodes</span><span class=p>)</span> 
</span></span></code></pre></td></tr></table></div></div><p>接著製作新的 output node。注意 name 和 size 都必須 match 最後一個 compute operator 的 output。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>new_output_node</span> <span class=o>=</span> <span class=n>onnx</span><span class=o>.</span><span class=n>helper</span><span class=o>.</span><span class=n>make_tensor_value_info</span><span class=p>(</span><span class=s1>&#39;resnetv15_stage1__plus0&#39;</span><span class=p>,</span> <span class=n>TensorProto</span><span class=o>.</span><span class=n>FLOAT</span><span class=p>,</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>56</span><span class=p>,</span> <span class=mi>56</span><span class=p>])</span> <span class=c1># stage1_plus0</span>
</span></span><span class=line><span class=cl><span class=k>del</span> <span class=n>model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>output</span><span class=p>[:]</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>output</span><span class=o>.</span><span class=n>extend</span><span class=p>([</span><span class=n>new_output_node</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>關於 output node 的 size，當然可以用算的，不過我推薦用 shape inference 跑一次原本的 ONNX 模型直接拿所有的 compute operator 的 output size。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>inferred_model</span> <span class=o>=</span> <span class=n>onnx</span><span class=o>.</span><span class=n>shape_inference</span><span class=o>.</span><span class=n>infer_shapes</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>inferred_model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>value_info</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span><span class=line><span class=cl><span class=c1># name: &#34;resnetv15_stage1__plus0&#34;</span>
</span></span><span class=line><span class=cl><span class=c1># type {</span>
</span></span><span class=line><span class=cl><span class=c1>#   tensor_type {</span>
</span></span><span class=line><span class=cl><span class=c1>#     elem_type: 1</span>
</span></span><span class=line><span class=cl><span class=c1>#     shape {</span>
</span></span><span class=line><span class=cl><span class=c1>#       dim {</span>
</span></span><span class=line><span class=cl><span class=c1>#         dim_value: 1</span>
</span></span><span class=line><span class=cl><span class=c1>#       }</span>
</span></span><span class=line><span class=cl><span class=c1>#       dim {</span>
</span></span><span class=line><span class=cl><span class=c1>#         dim_value: 64</span>
</span></span><span class=line><span class=cl><span class=c1>#       }</span>
</span></span><span class=line><span class=cl><span class=c1>#       dim {</span>
</span></span><span class=line><span class=cl><span class=c1>#         dim_value: 56</span>
</span></span><span class=line><span class=cl><span class=c1>#       }</span>
</span></span><span class=line><span class=cl><span class=c1>#       dim {</span>
</span></span><span class=line><span class=cl><span class=c1>#         dim_value: 56</span>
</span></span><span class=line><span class=cl><span class=c1>#       }</span>
</span></span><span class=line><span class=cl><span class=c1>#     }</span>
</span></span><span class=line><span class=cl><span class=c1>#   }</span>
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span></code></pre></td></tr></table></div></div><p>最後把修改完的模型儲存起來就大功告成了。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>onnx</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>&#39;resnet18-v1-7/stage1_plus0.onnx&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=結尾>結尾</h2><p>找資料的途中找到了很多大大寫的關於 ONNX 改圖的 script，像是<br><a href=https://blog.csdn.net/xxradon/article/details/104715524>https://blog.csdn.net/xxradon/article/details/104715524</a><br><a href=https://github.com/saurabh-shandilya/onnx-utils>https://github.com/saurabh-shandilya/onnx-utils</a></p><p>最後才發現有個工具叫 <a href=https://github.com/ZhangGe6/onnx-modifier>onnx-modifier</a> 可以用 UI 介面來修改 ONNX model，可以增減 node，看起來對於小規模的 ONNX 模型修改十分方便。用這個工具來修改 ResNet18 應該能很容易達到我要的目標 XD。<br>不過藉由這次機會深入了解 ONNX 的格式，對未來如果需要做更進階的操作應該會挺有幫助的。</p><iframe class=LikeCoin height=235 src="https://button.like.co/in/embed/yuko2926846/button?referrer=http%3a%2f%2fyuko29.github.io%2fpost%2fmodify-onnx-model%2f" width=100% frameborder=0></iframe></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Yuko Hu</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-06-30</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-sa/4.0/deed.zh-hant target=_blank>CC BY-SA 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/onnx/>onnx</a></div><nav class=post-nav><a class=prev href=/post/xv6-environment-setup/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Xv6 Environment Setup</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/2021-retrospect/><span class="next-text nav-default">2021 年度回顧</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><div id=disqus_thread></div><script type=text/javascript>(function(){if(window.location.hostname==="localhost")return;var t,e=document.createElement("script");e.type="text/javascript",e.async=!0,t="yuko29",e.src="//"+t+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:yuko29.hu@email.com class="iconfont icon-email" title=email></a><a href=http://github.com/yuko29 class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a>
</span><span class=copyright-year>&copy;
2020 -
2025<span class=heart><i class="iconfont icon-heart"></i></span><span>Yuko Hu</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script><script type=text/javascript>window.MathJax={tex:{}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NC0VXE56DE"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NC0VXE56DE")}</script></body></html>